{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page Rank Implementation\n",
    "\n",
    "PageRank is the underlying algorithm used by Google to rank websites in their search engine results. PageRank works by counting the number of links to a page to determine a ranking for the website. Higher-ranked websites have more links from other websites.\n",
    "\n",
    "This is a implementation of the Page Rank algorithm using Markov Chains.  Of all the implementations out there, I found the implementation by Daniel Bartolomé to be clean and computationally efficient.  It has been modified for better control on convergence and to return rank and convergence information.\n",
    "\n",
    "To use PageRank to rank websites, model the internet as a graph where websites are represented as vertices and edges are hyperlinks. The algorithm inputs the adjacency matrix corresponding to this graph and computes the PageRank score per vertex using Markov Chains. It outputs a descending ranked list of vertices (ranked websites).\n",
    "\n",
    "**Reference**\n",
    "*Daniel Bartolomé. Github. PageRank Implementation in R and Python. Last Accessed July 2018. [https://github.com/BartolomeD/pagerank](https://github.com/BartolomeD/pagerank).*\n",
    "\n",
    "*Sergei Brin and Lawrence Page. (1998). \"The anatomy of a large-scale hypertextual Web search engine\" (PDF). Computer Networks and ISDN Systems. 30: 107–117. Accessed July 2018. [http://infolab.stanford.edu/pub/papers/google.pdf](http://infolab.stanford.edu/pub/papers/google.pdf).*\n",
    "\n",
    "### Update the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /opt/conda/lib/python3.5/site-packages (18.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /opt/conda/lib/python3.5/site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /opt/conda/lib/python3.5/site-packages (from sklearn) (0.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in /opt/conda/lib/python3.5/site-packages (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas in /opt/conda/lib/python3.5/site-packages (0.23.3)\r\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /opt/conda/lib/python3.5/site-packages (from pandas) (2016.10)\r\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /opt/conda/lib/python3.5/site-packages (from pandas) (2.6.0)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /opt/conda/lib/python3.5/site-packages (from pandas) (1.15.0)\r\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/lib/python3.5/site-packages (from python-dateutil>=2.5.0->pandas) (1.10.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the Underlying environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Environment: Local\n"
     ]
    }
   ],
   "source": [
    "env = None\n",
    "colaboratory_flag = False\n",
    "try:\n",
    "    # This will work for everything but Google Colaboratory since the utility is somewhere on Google Drive\n",
    "    # which is not yet mounted and so it is not reachable.\n",
    "    #\n",
    "    from utilities.detect_environment import detect_environment\n",
    "\n",
    "    env = detect_environment()\n",
    "\n",
    "    print('Detected Environment: {}'.format(env))\n",
    "    if env.detected_environment == utilities.detect_environment.COLABORATORY:\n",
    "        colaboratory_flag = True\n",
    "    \n",
    "except:\n",
    "    # Check if on Colaboratory\n",
    "    import os\n",
    "    try:\n",
    "        os.environ['DATALAB_SETTINGS_OVERRIDES']\n",
    "        colaboratory_flag = True\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount Google Drive if on Colaboratory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if colaboratory_flag:\n",
    "    #colab\n",
    "    # google-drive-ocamlfuse\n",
    "    # https://github.com/astrada/google-drive-ocamlfuse\n",
    "    !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "    !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "    !apt-get update -qq 2>&1 > /dev/null\n",
    "    !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "\n",
    "    # Colab Auth token\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "\n",
    "    # Drive FUSE library credential\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "    creds = GoogleCredentials.get_application_default()\n",
    "    import getpass\n",
    "    !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "    vcode = getpass.getpass()\n",
    "    !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "\n",
    "    # drive/ Google Drive\n",
    "    !mkdir -p drive\n",
    "    !google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import utilities.setup_logging\n",
    "\n",
    "utilities.setup_logging.setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank Algorithm using Markov Chains\n",
    "\n",
    "The theory behind the PageRank algorithm holds that an imaginary surfer who is randomly surfing pages through links will eventually stop clicking. The probability at any step that the person will continue is representing as a damping factor. Various studies have tested different damping factors, but it is generally assumed that the damping factor will be set around 0.85.  Consider the implementation is the Markov chain:\n",
    "\n",
    "```python\n",
    "        for j in range(len(t)):\n",
    "            if sum(a[j, :]) == 0:\n",
    "                t[j] = 1 / ncol\n",
    "            else:\n",
    "                t[j] = (1-damping) / ncol + damping * sum(a[:, j] * (s[i, :] / np.sum(a, 1)))\n",
    "```\n",
    "\n",
    "`j` cycles over all the rows in the matrix.  For the jth row, if the sum of the row is zero, then initialize the influence to be equal ($\\frac{1}{N}$) and sum to one (probabilistic).\n",
    "\n",
    "For the jth row which has a sum not equal to zero, then the update rule at step ```j``` is given as a recursive probability $PR$ (the Markov Chain):\n",
    "\n",
    "$$PR(p_i;t+1) = \\frac{1-d}{N} + d \\sum_{p_i \\in M(p_i)} \\frac{PR(p_j, t)}{L(p_j)}$$\n",
    "\n",
    "where $N$ is the number of items, $d$ is the damping factor, and $L$ is the number of outbound links.  It is expressed in the else clause above.\n",
    "\n",
    "**References**\n",
    "*PageRank. Wikipedia. Accessed July 2018. [https://en.wikipedia.org/wiki/PageRank](https://en.wikipedia.org/wiki/PageRank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def pagerank(a, damping=0.85, convergence_tolerance=1.0e-9):\n",
    "    \n",
    "    # initialize transition matrix\n",
    "    ncol = a.shape[1]\n",
    "    logging.info('Operating on {} entities'.format(ncol))\n",
    "    # s is a row vector with even weighting between the ncol entities\n",
    "    s = np.repeat(1 / ncol, ncol).reshape(1, -1)\n",
    "    # initialize the counter\n",
    "    i = 0\n",
    "    \n",
    "    # run markov chain\n",
    "    while True:\n",
    "        \n",
    "        # transition vector at t + 1\n",
    "        t = np.empty(ncol)  # Start with an empty vector\n",
    "        for j in range(len(t)):\n",
    "            if sum(a[j, :]) == 0:\n",
    "                t[j] = 1 / ncol\n",
    "            else:\n",
    "                t[j] = (1-damping) / ncol + damping * sum(a[:, j] * (s[i, :] / np.sum(a, 1)))\n",
    "            \n",
    "\n",
    "        s = np.vstack([s, t])\n",
    "\n",
    "        i += 1\n",
    "        err = mean_squared_error(s[i - 1, :], s[i, :])\n",
    "        logging.info('Iteration {}: Approximate Error {}'.format(i, err))\n",
    "        \n",
    "        # break if converged\n",
    "        if (i > 0) and (err <= convergence_tolerance):\n",
    "            break\n",
    "    \n",
    "    # sort nodes\n",
    "    out = pd.Series(np.round(s[-1, :], 4)).reset_index().sort_values(0)[::-1].values\n",
    "    \n",
    "    # Gather sorted pagerank scores\n",
    "    scores = []\n",
    "    for node in range(ncol):\n",
    "        scores.append((int(out[node, 0]), np.round(out[node, 1], 4)))\n",
    "    return scores, i+1, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Input\n",
      "-------------\n",
      "[[0 1 0 1 1 0 0 1 1 0]\n",
      " [0 0 1 1 1 0 1 1 1 0]\n",
      " [1 1 1 1 0 0 1 0 1 1]\n",
      " [0 1 1 1 0 1 0 0 0 1]\n",
      " [0 1 1 0 1 1 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 1 1 1]\n",
      " [0 0 1 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 0 0 0 0 1]\n",
      " [1 0 1 1 0 0 1 0 1 0]\n",
      " [1 0 0 1 0 1 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "numpages = 10\n",
    "a = np.random.randint(0, 2, (numpages, numpages))\n",
    "print('Example Input')\n",
    "print('-------------')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Operating on 10 entities\n",
      "INFO:root:Iteration 1: Approximate Error 0.0003780591836734694\n",
      "INFO:root:Iteration 2: Approximate Error 5.001978882351782e-05\n",
      "INFO:root:Iteration 3: Approximate Error 1.9634518917326716e-06\n",
      "INFO:root:Iteration 4: Approximate Error 1.3804103089795372e-07\n",
      "INFO:root:Iteration 5: Approximate Error 1.143644825695597e-08\n",
      "INFO:root:Iteration 6: Approximate Error 4.827463122484251e-10\n"
     ]
    }
   ],
   "source": [
    "scores, numiterations, error = pagerank(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converted on iteration 7 with error 4.827463122484251e-10\n",
      "Item     Score\n",
      "   3    0.1311\n",
      "   2     0.124\n",
      "   8    0.1205\n",
      "   9    0.1094\n",
      "   4    0.0973\n",
      "   1    0.0951\n",
      "   7     0.087\n",
      "   0    0.0815\n",
      "   5    0.0813\n",
      "   6    0.0729\n"
     ]
    }
   ],
   "source": [
    "print('')\n",
    "print('Converted on iteration {} with error {}'.format(numiterations, error))\n",
    "print('Item     Score')\n",
    "for item in scores:\n",
    "    print('{:4}  {:8}'.format(item[0], item[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
